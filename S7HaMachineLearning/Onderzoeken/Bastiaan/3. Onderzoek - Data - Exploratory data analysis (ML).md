# 3. Onderzoek - Welke data?

## 3.1 Inleiding

In de hedendaagse digitale wereld speelt automatisering een cruciale rol, met name in het domein van slimme huizen. Home Assistant, een open-source platform voor home automation, biedt gebruikers de mogelijkheid om hun huishoudelijke apparaten en diensten aan te sturen. Het creëren van automatiseringen binnen Home Assistant kan complex zijn en vereist technische kennis en ervaring.

Dit onderzoek richt zich op de vraag: "Is de beschikbare data binnen Home Assistant voldoende en geschikt om machine learning modellen te trainen?" Het doel is om te onderzoeken of de data die gegenereerd wordt door Home Assistant kan worden gebruikt om machine learning modellen te trainen die automatiseringen(automations) kunnen genereren. De keuze hiervoor is om het creëren van automatiseringen(automations) te vereenvoudigen en de toegankelijkheid van home automation te vergroten.

In dit onderzoek ga ik volgens de Exploratory data analysis (ML) methode van ictresearchmethods.nl onderzoeken welke data er nodig is om een automation te genereren en hoe deze geschikt gemaakt kan worden om het model te trainen.

## Automating Home Assistant
Home Assistant bevat informatie over alle apparaten en diensten die geïntegreerd zijn in jouw omgeving. Deze informatie is beschikbaar voor de gebruiker in het dashboard. Deze informatie kan gebruikt worden om automations te maken.

Met automations in Home Assistant kun je automatisch reageren op dingen die gebeuren. Je kunt de lichten aanzetten bij zonsondergang of de muziek pauzeren als je gebeld wordt.
Andere voorbeelden kunnen zijn:
1. **Energiebesparing**: Een automation kan worden ingesteld om de thermostaat automatisch te verlagen wanneer niemand thuis is, en deze weer te verhogen wanneer iemand thuiskomt. Dit kan worden bereikt door de locatiegegevens van de smartphones van de bewoners te gebruiken.

**Veiligheid**: Een automation kan worden ingesteld om de buitenverlichting automatisch in te schakelen wanneer het donker wordt en deze weer uit te schakelen bij zonsopgang. Dit kan helpen om de veiligheid van het huis te verhogen.

**Gemak**: Een automation kan worden ingesteld om de koffiemachine automatisch aan te zetten op een bepaald tijdstip in de ochtend, zodat de koffie klaar is wanneer je opstaat. Dit kan worden bereikt door de koffiemachine te verbinden met een slimme stekker die kan worden bediend door Home Assistant.


<br>

## Exploratory data analysis (ML)
Om automatiseringen te genereren met behulp van machine learning, hebben we verschillende soorten data nodig die de componenten van een automation vertegenwoordigen: triggers, condities en acties.

**Triggers**: Triggers zijn gebeurtenissen die een automation starten. De data die we nodig hebben voor triggers kan afkomstig zijn van verschillende bronnen, zoals sensoren (bijvoorbeeld bewegingssensoren, deursensoren), tijdgegevens (bijvoorbeeld het tijdstip van de dag, de dag van de week), en apparaatstatussen (bijvoorbeeld of een apparaat aan of uit is). Deze data kan worden verzameld via de Home Assistant API, die toegang geeft tot de status van apparaten en sensoren in het systeem.

**Condities**: Condities zijn tests die bepalen of een automation moet doorgaan op basis van de huidige status van het systeem. De data die we nodig hebben voor condities kan ook afkomstig zijn van sensoren, tijdgegevens en apparaatstatussen, evenals van andere bronnen zoals weergegevens (bijvoorbeeld of het buiten regent of zonnig is). Deze data kan ook worden verzameld via de Home Assistant API.

**Acties**: Acties zijn de taken die worden uitgevoerd wanneer een automation wordt getriggerd en alle condities zijn voldaan. De data die we nodig hebben voor acties omvat de lijst van beschikbare acties in het systeem (bijvoorbeeld een licht inschakelen, de temperatuur van een thermostaat instellen), evenals de status van deze acties (bijvoorbeeld of een licht aan of uit is). Deze data kan worden verzameld door de beschikbare services en hun statussen op te vragen via de Home Assistant API.

Door deze data te verzamelen en te analyseren, kunnen we een beter begrip krijgen van de patronen en relaties die bestaan tussen verschillende triggers, condities en acties. Dit kan ons helpen bij het ontwikkelen van een machine learning model dat in staat is om effectieve automatiseringen te genereren op basis van deze patronen en relaties.

Voorbeeld voor een automation:
``` 
Wanneer Henk thuiskomt en het is na zonsondergang: Doe het licht aan in de woonkamer.
```

De automation is op te delen in de volgende drie delen:
- (trigger) Wanneer Henk thuiskomt
- (conditie) en het is na zonsondergang:
- (actie) doe het licht aan in de woonkamer

Het eerste deel is de trigger van de automation. Triggers beschrijven gebeurtenissen
 die de automation moeten triggeren. In dit geval is het een persoon die thuiskomt(Henk), dit kan worden waargenomen in Home Assistant door de status in de gaten te houden, dit gebeurt met behulp van apparaten/sensoren. Wanneer de status van Henk verandert van niet_thuis naar thuis.

Het tweede deel is de conditie(condition). Condities zijn optionele tests om een automation uit te voeren onder bepaalde omstandigheden of situaties. Een conditie test tegen de huidige status in het systeem. Dit kan zijn: de huidige tijd, apparaten, mensen en andere dingen zoals wanneer de zon op komt of onder gaat. In dit geval willen we alleen handelen als de zon onder is.

Het derde deel is de actie(action), die wordt uitgevoerd wanneer een regel wordt getriggerd en aan alle condities is voldaan. Het kan bijvoorbeeld een licht inschakelen, de temperatuur van uw thermostaat instellen of een scène activeren.

Voorbeeld van een automation:
``` YAML
alias: Turn on Living Room Lights when Henk arrives home
trigger:
  platform: state
  entity_id: device_tracker.Henk
  to: 'home'
condition:
  condition: sun
  after: sunset
action:
  service: light.turn_on
  entity_id: light.living_room

```

<br>

## Waarom?
Het gebruik van machine learning om automations te genereren binnen Home Assistant heeft verschillende voordelen die de gebruikerservaring kunnen verbeteren:

**Personalisatie**: Machine learning kan patronen en trends in de data herkennen die een gebruiker misschien niet zou opmerken. Dit kan leiden tot automations die beter afgestemd zijn op de behoeften en het gedrag van de gebruiker. 

**Efficiëntie**: Het handmatig creëren van automations kan tijdrovend en complex zijn, vooral voor gebruikers die niet technisch onderlegd zijn. Machine learning kan dit proces automatiseren, waardoor gebruikers tijd besparen en de drempel voor het gebruik van automations wordt verlaagd.

**Adaptiviteit**: Machine learning modellen kunnen leren en zich aanpassen naarmate er meer data ontvangen wordt. Dit betekent dat de automations die genereert worden in de loop der tijd kunnen verbeteren en zich kunnen aanpassen aan veranderende omstandigheden of het gedrag van de gebruiker.

**Innovatie**: Door machine learning te gebruiken om automations te genereren, kunnen we nieuwe mogelijkheden ontdekken die we misschien niet hadden overwogen bij het handmatig creëren van automations. 

Door deze voordelen kan het gebruik van machine learning om automations te genereren de gebruikerservaring van Home Assistant aanzienlijk verbeteren, waardoor het platform toegankelijker en nuttiger wordt voor een breder scala aan gebruikers.

Het bestandsformaat wat Home Assistant gebruikt om automations te genereren is YAML. Elke gebruiker van Home Assistant heeft zijn eigen manier van noteren. Daarom richt ik mij op de basis en richtlijnen van Home Assistant. Home Assistant kent "Blue prints", deze blue prints maken het mogelijk om makkelijk automations tussen verschillende systemen uit te wisselen. [About Blueprints](https://community.home-assistant.io/t/about-blueprints/253788)

Deze wil ik gaan gebruiken als basis voor het trainen van een model.

<br>

## Hoe?
### Data voorbereiding
Data voorbereiding is een cruciale stap in elk machine learning project. Het is het proces waarbij ruwe data wordt getransformeerd en georganiseerd in een formaat dat geschikt is voor modeltraining. De kwaliteit en bruikbaarheid van de data heeft direct invloed op hoe goed het machine learning model kan presteren. Onvolledige, onnauwkeurige of onvolledige data kan leiden tot verkeerde resultaten en een slechte modelprestatie.

#### Data verzameling
Voor dit project heb ik data verzameld in de vorm van YAML-bestanden die Home Assistant automations bevatten. Deze bestanden zijn afkomstig van het Home Assistant documentatie forum en bevatten de definities van verschillende automations die zijn ingesteld door een gebruiker. Elke automation in deze bestanden is gedefinieerd in YAML-formaat, wat staat voor "YAML Ain't Markup Language". Het is een mensvriendelijk data formaat dat vaak wordt gebruikt voor configuratiebestanden en in toepassingen waar data wordt opgeslagen of verzonden.

#### Data conversie:
Om de YAML-bestanden te kunnen verwerken, hebben we ze omgezet naar Python-dictionaries met behulp van de PyYAML-bibliotheek. Dit maakt het gemakkelijker om de data te manipuleren en te analyseren. Bijvoorbeeld, een YAML-bestand dat er zo uitziet:
``` YAML
alias: Turn on the light
trigger:
  platform: state
  entity_id: switch.button
  to: 'on'
action:
  service: light.turn_on
  target:
    entity_id: light.living_room
```

wordt omgezet naar de volgende Python-dictionary:

``` Python
{
  'alias': 'Turn on the light',
  'trigger': {
    'platform': 'state',
    'entity_id': 'switch.button',
    'to': 'on'
  },
  'action': {
    'service': 'light.turn_on',
    'target': {
      'entity_id': 'light.living_room'
    }
  }
}
```
#### Data verwerking
Na de conversie heb ik de triggers, condities en acties in de automations verwerkt. Elke automation bestaat uit een of meer triggers, nul of meer condities, en een of meer acties. Deze hebben elk verschillende velden, afhankelijk van hun type. Bijvoorbeeld, een 'state'-trigger heeft een 'entity_id' en een 'to'-veld, terwijl een 'time'-trigger een 'at'-veld heeft. We hebben deze velden verwerkt en omgezet naar een gestandaardiseerd formaat dat geschikt is voor modeltraining.

#### Data correctie
Tijdens de data verwerking hebben we ook eventuele fouten in de YAML-bestanden gecorrigeerd. Dit omvatte het oplossen van syntaxisfouten, het verwijderen van ongebruikte velden en het corrigeren van ongeldige waarden. Dit heeft geholpen om de kwaliteit en consistentie van de data te waarborgen.

#### Conclusie van data voorbereiding:
1. Er waren enkele problemen met de gegevens, waaronder onnodige kolommen, kolommen die niet in in de bruikbare datatypes waren, onleesbare en ontbrekende waarden.

2. Om deze problemen op te lossen, werden de volgende stappen ondernomen:
   - Onnodige kolommen werden verwijderd.
   - De juiste datatypes werden vervangen in hun respectieve kolommen.
   - De gegevenswaarden werden hernoemd voor betere leesbaarheid.
   - Ontbrekende waarden werden geïmputeerd. [Imputation - statistics - Wikipedia](https://en.wikipedia.org/wiki/Imputation_(statistics))

3. Er werden nieuwe functies gecreëerd door sommige kolommen die met elkaar verband hielden samen te voegen om onnodige functies te vermijden. De originele kolommen werden vervolgens verwijderd omdat ze niet langer nodig waren.

4. De gegevens werden gecontroleerd op onbalans en vervolgens gebalanceerd.

5. De gegevens werden gesplitst in trainings- en evaluatie/testsets.

6. De functies werden gecodeerd en geschaald met behulp van de LabelEncoder om de doelkolom om te zetten in getallen die ML-modellen kunnen begrijpen.

Dit waren de belangrijkste stappen in de data voorbereiding en verwerking.

### Feature engineering
**Introductie**:
Feature Engineering is een cruciaal onderdeel van het bouwen van een effectief machine learning model. Het is het proces van het creëren van nieuwe functies of het modificeren van bestaande functies die de prestaties van het model kunnen verbeteren. Deze functies worden afgeleid van de ruwe gegevens en kunnen helpen om complexe patronen in de gegevens beter vast te leggen.

In het kader van dit project, waar ik een model bouw om automations te genereren, is feature engineering bijzonder belangrijk. De gegevens die ik gebruik bestaan uit verschillende automations, elk met verschillende parameters zoals triggers, condities en acties. Deze parameters zijn op zichzelf al functies, maar deze te transformeren of te combineren is het mogelijk nieuwe, informatieve functies creëren.

Bijvoorbeeld, er kunnen nieuwe functies gemaakt worden die de complexiteit van een automation meten, zoals het aantal acties of de diversiteit van de gebruikte services. Er kunnen ook functies gemaakt worden die de relaties tussen verschillende parameters vastleggen, zoals bij een bepaalde actie altijd volgt op een bepaalde trigger.

Het doel van feature engineering in dit project is om functies te creëren die het model helpen om de onderliggende patronen in de gegevens te leren, zodat het nauwkeurige en bruikbare automations kan genereren.

2. **Data Analyse**: Bespreek hoe de gegevens hebt geanalyseerd om te bepalen welke functies mogelijk nuttig zouden zijn. Dit kan het bekijken van correlaties tussen variabelen, het analyseren van de verdeling van variabelen, enz. omvatten.

3. **Feature Creatie**: Beschrijf de nieuwe functies die je hebt gecreëerd. Dit kan het combineren van bestaande functies, het creëren van polynomiale functies, het extraheren van informatie uit datums of tekst, enz. zijn. Leg uit waarom je denkt dat deze nieuwe functies nuttig kunnen zijn.

4. **Feature Selectie**: Leg uit hoe je hebt besloten welke functies je in je model wilt opnemen. Dit kan het gebruik van statistische tests, het belang van functies in een voorlopig model, of andere methoden omvatten.

5. **Feature Transformatie**: Bespreek eventuele transformaties die je op je functies hebt toegepast. Dit kan het normaliseren of standaardiseren van functies, het toepassen van logaritmische of andere transformaties om de verdeling van een functie te veranderen, enz. zijn.

6. **Conclusie**: Sluit af met een samenvatting van wat je hebt gedaan en eventuele inzichten die je hebt opgedaan uit het proces van feature engineering. Je kunt ook eventuele beperkingen of mogelijke verbeteringen voor toekomstig werk bespreken.

### Model selectie

### Model training

### Model implementatie



<br>

## Conclusie:


<br>

## Bronnen

AWS open source newsletter, #158 door Ricardo Sueiras: Dit artikel bevat een nieuwsbrief over open source projecten op AWS, waaronder enkele gerelateerd aan machine learning en model deployment.
https://dev.to/aws/aws-open-source-newsletter-158-178k

Mastering Your AI Coworker: A Developer's Guide to ChatGPT door Andreas Bergström: Dit artikel biedt een diepgaande gids over hoe je kunt werken met AI zoals ChatGPT, wat nuttig kan zijn bij het begrijpen van hoe je je eigen machine learning model kunt inzetten.
https://dev.to/andreasbergstrom/mastering-your-ai-coworker-a-developers-guide-to-chatgpt-1gea

Build LLM-powered chatbot in 5 minutes using HugChat and Streamlit door Vishnu Sivan: Dit artikel laat zien hoe je snel een chatbot kunt bouwen met behulp van machine learning, wat je kan helpen bij het begrijpen van de stappen die nodig zijn om een model te implementeren.
https://dev.to/codemaker2015/build-llm-powered-chatbot-in-5-minutes-using-hugchat-and-streamlit-2f53

DevOps Toolchain and Technologies door Rain Leander: Dit artikel bespreekt verschillende DevOps-tools en technologieën, die nuttig kunnen zijn bij het implementeren van machine learning modellen.
https://dev.to/rainleander/devops-toolchain-and-technologies-3n0k

Applying a MLOps approach to Federated learning using ML Flow with NV Flare: A Healthcare use case door Bart: Dit artikel bespreekt hoe je een MLOps-aanpak kunt toepassen op federatief leren, wat nuttig kan zijn bij het begrijpen van hoe je machine learning modellen kunt implementeren in een gedistribueerde omgeving.
https://dev.to/dataroots/applying-a-mlops-approach-to-federated-learning-using-ml-flow-with-nv-flare-a-healthcare-use-case-5e2n