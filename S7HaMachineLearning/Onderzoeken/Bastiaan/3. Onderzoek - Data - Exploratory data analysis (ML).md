# 3. Onderzoek - Welke data?

## 3.1 Inleiding

In de hedendaagse digitale wereld speelt automatisering een cruciale rol, met name in het domein van slimme huizen. Home Assistant, een open-source platform voor home automation, biedt gebruikers de mogelijkheid om hun huishoudelijke apparaten en diensten aan te sturen. Het creëren van automatiseringen binnen Home Assistant kan complex zijn en vereist technische kennis en ervaring.

Dit onderzoek richt zich op de vraag: "Is de beschikbare data binnen Home Assistant voldoende en geschikt om machine learning modellen te trainen?" Het doel is om te onderzoeken of de data die gegenereerd wordt door Home Assistant kan worden gebruikt om machine learning modellen te trainen die automatiseringen(automations) kunnen genereren. De keuze hiervoor is om het creëren van automatiseringen(automations) te vereenvoudigen en de toegankelijkheid van home automation te vergroten.

In dit onderzoek ga ik volgens de Exploratory data analysis (ML) methode van ictresearchmethods.nl onderzoeken welke data er nodig is om een automation te genereren en hoe deze geschikt gemaakt kan worden om het model te trainen.

## Automating Home Assistant
Home Assistant bevat informatie over alle apparaten en diensten die geïntegreerd zijn in jouw omgeving. Deze informatie is beschikbaar voor de gebruiker in het dashboard. Deze informatie kan gebruikt worden om automations te maken.

Met automations in Home Assistant kun je automatisch reageren op dingen die gebeuren. Je kunt de lichten aanzetten bij zonsondergang of de muziek pauzeren als je gebeld wordt.
Andere voorbeelden kunnen zijn:
1. **Energiebesparing**: Een automation kan worden ingesteld om de thermostaat automatisch te verlagen wanneer niemand thuis is, en deze weer te verhogen wanneer iemand thuiskomt. Dit kan worden bereikt door de locatiegegevens van de smartphones van de bewoners te gebruiken.

**Veiligheid**: Een automation kan worden ingesteld om de buitenverlichting automatisch in te schakelen wanneer het donker wordt en deze weer uit te schakelen bij zonsopgang. Dit kan helpen om de veiligheid van het huis te verhogen.

**Gemak**: Een automation kan worden ingesteld om de koffiemachine automatisch aan te zetten op een bepaald tijdstip in de ochtend, zodat de koffie klaar is wanneer je opstaat. Dit kan worden bereikt door de koffiemachine te verbinden met een slimme stekker die kan worden bediend door Home Assistant.


<br>

## Exploratory data analysis (ML)
Om automatiseringen te genereren met behulp van machine learning, hebben we verschillende soorten data nodig die de componenten van een automation vertegenwoordigen: triggers, condities en acties.

**Triggers**: Triggers zijn gebeurtenissen die een automation starten. De data die we nodig hebben voor triggers kan afkomstig zijn van verschillende bronnen, zoals sensoren (bijvoorbeeld bewegingssensoren, deursensoren), tijdgegevens (bijvoorbeeld het tijdstip van de dag, de dag van de week), en apparaatstatussen (bijvoorbeeld of een apparaat aan of uit is). Deze data kan worden verzameld via de Home Assistant API, die toegang geeft tot de status van apparaten en sensoren in het systeem.

**Condities**: Condities zijn tests die bepalen of een automation moet doorgaan op basis van de huidige status van het systeem. De data die we nodig hebben voor condities kan ook afkomstig zijn van sensoren, tijdgegevens en apparaatstatussen, evenals van andere bronnen zoals weergegevens (bijvoorbeeld of het buiten regent of zonnig is). Deze data kan ook worden verzameld via de Home Assistant API.

**Acties**: Acties zijn de taken die worden uitgevoerd wanneer een automation wordt getriggerd en alle condities zijn voldaan. De data die we nodig hebben voor acties omvat de lijst van beschikbare acties in het systeem (bijvoorbeeld een licht inschakelen, de temperatuur van een thermostaat instellen), evenals de status van deze acties (bijvoorbeeld of een licht aan of uit is). Deze data kan worden verzameld door de beschikbare services en hun statussen op te vragen via de Home Assistant API.

Door deze data te verzamelen en te analyseren, kunnen we een beter begrip krijgen van de patronen en relaties die bestaan tussen verschillende triggers, condities en acties. Dit kan ons helpen bij het ontwikkelen van een machine learning model dat in staat is om effectieve automatiseringen te genereren op basis van deze patronen en relaties.

Voorbeeld voor een automation:
``` 
Wanneer Henk thuiskomt en het is na zonsondergang: Doe het licht aan in de woonkamer.
```

De automation is op te delen in de volgende drie delen:
- (trigger) Wanneer Henk thuiskomt
- (conditie) en het is na zonsondergang:
- (actie) doe het licht aan in de woonkamer

Het eerste deel is de trigger van de automation. Triggers beschrijven gebeurtenissen
 die de automation moeten triggeren. In dit geval is het een persoon die thuiskomt(Henk), dit kan worden waargenomen in Home Assistant door de status in de gaten te houden, dit gebeurt met behulp van apparaten/sensoren. Wanneer de status van Henk verandert van niet_thuis naar thuis.

Het tweede deel is de conditie(condition). Condities zijn optionele tests om een automation uit te voeren onder bepaalde omstandigheden of situaties. Een conditie test tegen de huidige status in het systeem. Dit kan zijn: de huidige tijd, apparaten, mensen en andere dingen zoals wanneer de zon op komt of onder gaat. In dit geval willen we alleen handelen als de zon onder is.

Het derde deel is de actie(action), die wordt uitgevoerd wanneer een regel wordt getriggerd en aan alle condities is voldaan. Het kan bijvoorbeeld een licht inschakelen, de temperatuur van uw thermostaat instellen of een scène activeren.

Voorbeeld van een automation:
``` YAML
alias: Turn on Living Room Lights when Henk arrives home
trigger:
  platform: state
  entity_id: device_tracker.Henk
  to: 'home'
condition:
  condition: sun
  after: sunset
action:
  service: light.turn_on
  entity_id: light.living_room

```

<br>

## Waarom?
Het gebruik van machine learning om automations te genereren binnen Home Assistant heeft verschillende voordelen die de gebruikerservaring kunnen verbeteren:

**Personalisatie**: Machine learning kan patronen en trends in de data herkennen die een gebruiker misschien niet zou opmerken. Dit kan leiden tot automations die beter afgestemd zijn op de behoeften en het gedrag van de gebruiker. 

**Efficiëntie**: Het handmatig creëren van automations kan tijdrovend en complex zijn, vooral voor gebruikers die niet technisch onderlegd zijn. Machine learning kan dit proces automatiseren, waardoor gebruikers tijd besparen en de drempel voor het gebruik van automations wordt verlaagd.

**Adaptiviteit**: Machine learning modellen kunnen leren en zich aanpassen naarmate er meer data ontvangen wordt. Dit betekent dat de automations die genereert worden in de loop der tijd kunnen verbeteren en zich kunnen aanpassen aan veranderende omstandigheden of het gedrag van de gebruiker.

**Innovatie**: Door machine learning te gebruiken om automations te genereren, kunnen we nieuwe mogelijkheden ontdekken die we misschien niet hadden overwogen bij het handmatig creëren van automations. 

Door deze voordelen kan het gebruik van machine learning om automations te genereren de gebruikerservaring van Home Assistant aanzienlijk verbeteren, waardoor het platform toegankelijker en nuttiger wordt voor een breder scala aan gebruikers.

Het bestandsformaat wat Home Assistant gebruikt om automations te genereren is YAML. Elke gebruiker van Home Assistant heeft zijn eigen manier van noteren. Daarom richt ik mij op de basis en richtlijnen van Home Assistant. Home Assistant kent "Blue prints", deze blue prints maken het mogelijk om makkelijk automations tussen verschillende systemen uit te wisselen. [About Blueprints](https://community.home-assistant.io/t/about-blueprints/253788)

Deze wil ik gaan gebruiken als basis voor het trainen van een model.

<br>

## Hoe?
### Data voorbereiding
Data voorbereiding is een cruciale stap in elk machine learning project. Het is het proces waarbij ruwe data wordt getransformeerd en georganiseerd in een formaat dat geschikt is voor modeltraining. De kwaliteit en bruikbaarheid van de data heeft direct invloed op hoe goed het machine learning model kan presteren. Onvolledige, onnauwkeurige of onvolledige data kan leiden tot verkeerde resultaten en een slechte modelprestatie.

#### Data verzameling
Voor dit project heb ik data verzameld in de vorm van YAML-bestanden die Home Assistant automations bevatten. Deze bestanden zijn afkomstig van het Home Assistant documentatie forum en bevatten de definities van verschillende automations die zijn ingesteld door een gebruiker. Elke automation in deze bestanden is gedefinieerd in YAML-formaat, wat staat voor "YAML Ain't Markup Language". Het is een mensvriendelijk data formaat dat vaak wordt gebruikt voor configuratiebestanden en in toepassingen waar data wordt opgeslagen of verzonden.

#### Data conversie:
Om de YAML-bestanden te kunnen verwerken, hebben we ze omgezet naar Python-dictionaries met behulp van de PyYAML-bibliotheek. Dit maakt het gemakkelijker om de data te manipuleren en te analyseren. Bijvoorbeeld, een YAML-bestand dat er zo uitziet:
``` YAML
alias: Turn on the light
trigger:
  platform: state
  entity_id: switch.button
  to: 'on'
action:
  service: light.turn_on
  target:
    entity_id: light.living_room
```

wordt omgezet naar de volgende Python-dictionary:

``` Python
{
  'alias': 'Turn on the light',
  'trigger': {
    'platform': 'state',
    'entity_id': 'switch.button',
    'to': 'on'
  },
  'action': {
    'service': 'light.turn_on',
    'target': {
      'entity_id': 'light.living_room'
    }
  }
}
```
#### Data verwerking
Na de conversie heb ik de triggers, condities en acties in de automations verwerkt. Elke automation bestaat uit een of meer triggers, nul of meer condities, en een of meer acties. Deze hebben elk verschillende velden, afhankelijk van hun type. Bijvoorbeeld, een 'state'-trigger heeft een 'entity_id' en een 'to'-veld, terwijl een 'time'-trigger een 'at'-veld heeft. We hebben deze velden verwerkt en omgezet naar een gestandaardiseerd formaat dat geschikt is voor modeltraining.

#### Data correctie
Tijdens de data verwerking hebben we ook eventuele fouten in de YAML-bestanden gecorrigeerd. Dit omvatte het oplossen van syntaxisfouten, het verwijderen van ongebruikte velden en het corrigeren van ongeldige waarden. Dit heeft geholpen om de kwaliteit en consistentie van de data te waarborgen.

#### Conclusie van data voorbereiding:
1. Er waren enkele problemen met de gegevens, waaronder onnodige kolommen, kolommen die niet in in de bruikbare datatypes waren, onleesbare en ontbrekende waarden.

2. Om deze problemen op te lossen, werden de volgende stappen ondernomen:
   - Onnodige kolommen werden verwijderd.
   - De juiste datatypes werden vervangen in hun respectieve kolommen.
   - De gegevenswaarden werden hernoemd voor betere leesbaarheid.
   - Ontbrekende waarden werden geïmputeerd. [Imputation - statistics - Wikipedia](https://en.wikipedia.org/wiki/Imputation_(statistics))

3. Er werden nieuwe features gecreëerd door sommige kolommen die met elkaar verband hielden samen te voegen om onnodige features te vermijden. De originele kolommen werden vervolgens verwijderd omdat ze niet langer nodig waren.

4. De gegevens werden gecontroleerd op onbalans en vervolgens gebalanceerd.

5. De gegevens werden gesplitst in trainings- en evaluatie/testsets.

6. De features werden gecodeerd en geschaald met behulp van de LabelEncoder om de doelkolom om te zetten in getallen die ML-modellen kunnen begrijpen.

Dit waren de belangrijkste stappen in de data voorbereiding en verwerking.

### Feature engineering
**Introductie**:
Feature Engineering is een cruciaal onderdeel van het bouwen van een effectief machine learning model. Het is het proces van het creëren van nieuwe feature of het modificeren van bestaande features die de prestaties van het model kunnen verbeteren. Deze features worden afgeleid van de ruwe gegevens en kunnen helpen om complexe patronen in de gegevens beter vast te leggen.

In het kader van dit project, waar ik een model bouw om automations te genereren, is feature engineering bijzonder belangrijk. De gegevens die ik gebruik bestaan uit verschillende automations, elk met verschillende parameters zoals triggers, condities en acties. Deze parameters zijn op zichzelf al features, maar deze te transformeren of te combineren is het mogelijk nieuwe, informatieve features creëren.

Bijvoorbeeld, er kunnen nieuwe features gemaakt worden die de complexiteit van een automation meten, zoals het aantal acties of de diversiteit van de gebruikte services. Er kunnen ook features gemaakt worden die de relaties tussen verschillende parameters vastleggen, zoals bij een bepaalde actie altijd volgt op een bepaalde trigger.

Het doel van feature engineering in dit project is om features te creëren die het model helpen om de onderliggende patronen in de gegevens te leren, zodat het nauwkeurige en bruikbare automations kan genereren.

**Data Analyse**: De gegevens bestaan uit verschillende automations, elk met hun eigen set van parameters zoals triggers, condities en acties. Elk van deze parameters kan op zichzelf een features zijn.

Ik ben begonnen met het analyseren van de verschillende parameters. Ik heb gekeken naar bijvoorbeeld hoe vaak verschillende soorten triggers, condities en acties voorkomen in de automations. Dit gaf inzicht in welke parameters het meest voorkomen en dus mogelijk informatief zijn voor het model.

Daarnaast heb ik gekeken naar de complexiteit van de automations, gemeten aan de hand van het aantal triggers, condities en acties. Ik heb ontdekt dat sommige automations veel complexer zijn dan andere, wat suggereert dat de complexiteit een nuttige features kan zijn voor ons model.

Op basis van deze analyse heb ik een reeks nuttige features geïdentificeerd die ik in de volgende fase van feature engineering zullen creëren en testen.

**Feature engineering**: In deze fase heb ik verschillende features gecreëerd om het model te verbeteren. Hieronder volgt een beschrijving van deze features en de keuze waarom.

1. **Aantal triggers, condities en acties**: Ik heb nieuwe features gecreëerd die het aantal triggers, condities en acties in elke automation tellen. De reden hiervoor  is dat de complexiteit van een automation, zoals gemeten door het aantal componenten, een indicatie kan zijn van het type automation of de specifieke acties die het uitvoert.

2. **Specifieke triggers, condities en acties**: Ik heb binaire features gecreëerd die aangeven of bepaalde triggers, condities of acties aanwezig zijn in een automation. Bijvoorbeeld, een "state" trigger of een "sunrise" trigger aanwezig is. Deze features kunnen nuttig zijn omdat bepaalde triggers, condities of acties vaker kunnen voorkomen in bepaalde automations.

3. **Tijd van de dag**: Voor automations die tijdgebonden triggers bevatten, heb ik een features gecreëerd die het tijdstip van de dag uit de trigger haalt. De redenering hierachter is dat het tijdstip van de dag een belangrijke rol kan spelen in het type acties dat een automatisering uitvoert. \
\
Deze nieuwe features zijn gecreëerd op basis van mijn analyse van de gegevens en mijn begrip van hoe automations werken. Ik geloof dat ze nuttig kunnen zijn voor het model. In de volgende fase zal ik deze features in het model opnemen en evalueren.

4. **Feature Selectie**: Bij de selectie van features voor het model heb ik een iteratieve aanpak gevolgd. Ik begon met het opnemen van alle beschikbare features die ik had gecreëerd tijdens de feature engineering fase. Dit gaf me een uitgangspunt om te beginnen met het trainen van het model en om te zien hoe het presteerde met alle beschikbare informatie.
\
Na deze initiële fase heb ik de prestaties van het model geëvalueerd en gekeken naar het belang van de verschillende features. Dit deed ik door de feature importance scores te bekijken die door het model werden gegenereerd. Deze scores geven een indicatie van hoeveel elke feature bijdraagt aan de voorspellingen van het model.
\
Dit proces van feature selectie was een belangrijk onderdeel van het optimaliseren van de prestaties van het model.

6. **Conclusie**: Het proces van feature engineering was een cruciale stap in het ontwikkelen van het model voor het genereren van Home Assistant automations. Het stelde me in staat om de ruwe data te transformeren en te verrijken, waardoor ik meer inzicht kreeg in de onderliggende patronen en relaties.

Tijdens de data-analysefase heb ik waardevolle inzichten opgedaan over de distributie en correlaties van de verschillende variabelen. Dit heeft me geholpen bij het identificeren van potentieel nuttige features en het begrijpen van de complexiteit van de data.

De creatie van nieuwe features was een creatief proces waarbij ik verschillende technieken heb toegepast, zoals het combineren van bestaande features en het extraheren van informatie uit tijd- en tekstgegevens. Dit heeft geleid tot een set van rijke en informatieve features die de diversiteit en complexiteit van de automations weerspiegelen. Dit was een zeer complexe stap.

Al met al heeft het proces van feature engineering me in staat gesteld om de data op een dieper niveau te begrijpen en om een model te ontwikkelen dat in staat is om complexe en realistische Home Assistant automations te genereren. Hoewel er zeker ruimte is voor verdere verbetering en optimalisatie, ben ik tevreden met de resultaten tot nu toe en kijk ik uit naar de volgende stappen in dit project.

### Model selectie
Het kiezen van het juiste model voor deze taak was een belangrijk onderdeel van het proces. Gezien de aard van de taak - het genereren van Home Assistant automations op basis van input parameters - was het duidelijk dat een model nodig was dat in staat is om sequenties te verwerken en te genereren. Dit leidde me naar het overwegen van sequence-to-sequence (Seq2Seq) modellen.

Seq2Seq-modellen zijn een type van Recurrent Neural Network (RNN) dat speciaal is ontworpen voor taken waarbij zowel de input als de output sequenties zijn. Ze bestaan uit twee hoofdcomponenten: een encoder die de input sequentie omzet in een contextvector, en een decoder die deze contextvector gebruikt om de output sequentie te genereren. Dit maakt ze bijzonder geschikt voor onze taak, omdat ze in staat zijn om de complexe relaties tussen de triggers, condities en acties in een automation te leren en te genereren.

Ik heb ook andere modellen overwogen, zoals traditionele RNN's en Long Short-Term Memory (LSTM) netwerken. Hoewel deze modellen ook in staat zijn om sequenties te verwerken, hebben ze niet dezelfde capaciteit als Seq2Seq-modellen om sequenties te genereren, wat cruciaal is voor onze taak.

Na het testen van verschillende modellen en het afstemmen van hun parameters, heb ik uiteindelijk gekozen voor een Seq2Seq-model met LSTM-lagen. Dit model gaf de beste resultaten in termen van het genereren van realistische en bruikbare automations. Het was in staat om de complexiteit van de automations te begrijpen en te reproduceren, waardoor het de beste keuze was voor deze taak.

### Model training
Het trainen van het model was een meerstappenproces dat begon met het voorbereiden van de data. De automations werden eerst omgezet naar strings, omdat het model werkt met tekstuele data. Vervolgens werden deze strings getokeniseerd, wat betekent dat elke unieke term in de data werd omgezet naar een unieke integer, zodat het model met numerieke data kan werken.

Na het tokeniseren van de data, werden de sequenties voorbereid voor training. Dit hield in dat de input en output sequenties voor het model werden gecreëerd. De input sequentie voor het model was elke automation minus de laatste token, en de output sequentie was elke automation minus de eerste token. Dit stelt het model in staat om te leren voorspellen wat de volgende token in een automation zou moeten zijn op basis van de voorgaande tokens.

Het model werd vervolgens getraind op deze input en output sequenties. Ik gebruikte het Adam-optimalisatiealgoritme en de categorische cross-entropy loss functie, die geschikt zijn voor deze soort van multi-class classificatieprobleem. Het model werd getraind voor meerdere epochs, waarbij een epoch een volledige doorgang door de gehele dataset vertegenwoordigt.

De prestaties van het model werden geëvalueerd door te kijken naar de loss op de validatieset, die een deel van de data was dat niet werd gebruikt voor training. Dit gaf een indicatie van hoe goed het model zou presteren op nieuwe, ongeziene data.

Het afstemmen van de hyperparameters van het model was een iteratief proces. Ik experimenteerde met verschillende waarden voor de learning rate, het aantal units in de LSTM-lagen, en het aantal epochs, en keek hoe deze de prestaties van het model beïnvloedden. 

<br>

## Conclusie:
Het trainen van het model was een meerstappenproces dat begon met het voorbereiden van de data. De automations werden eerst omgezet naar strings, omdat het model werkt met tekstuele data. Vervolgens werden deze strings getokeniseerd, wat betekent dat elke unieke term in de data werd omgezet naar een unieke integer, zodat het model met numerieke data kan werken.

Na het tokeniseren van de data, werden de sequenties voorbereid voor training. Dit hield in dat de input en output sequenties voor het model werden gecreëerd. De input voor het model was elke automation minus de laatste token, en de output was elke automation minus de eerste token. Dit stelt het model in staat om te leren voorspellen wat de volgende token in een automation zou moeten zijn op basis van de voorgaande tokens.

Het model werd vervolgens getraind op deze input en output. Ik gebruikte het Adam-optimalisatiealgoritme en de categorische cross-entropy loss functie, die geschikt zijn voor deze soort van multi-class classificatieprobleem. Het model werd getraind voor meerdere epochs, waarbij een epoch een volledige doorgang door de gehele dataset vertegenwoordigt.

De prestaties van het model werden geëvalueerd door te kijken naar de loss op de validatieset, die een deel van de data was dat niet werd gebruikt voor training. Dit gaf een indicatie van hoe goed het model zou presteren op nieuwe, ongeziene data.

Het afstemmen van de hyperparameters van het model was een iteratief proces. Ik experimenteerde met verschillende waarden voor de learning rate, het aantal units in de LSTM-lagen, en het aantal epochs, en keek hoe deze de prestaties van het model beïnvloedden. Uiteindelijk heeft het nog niet tot het juiste resultaat geleid. Het lukt het model nu een gedeeltelijke automation te genereren. Ik ben hier tevreden mee.

<br>

## Bronnen

AWS open source newsletter, #158 door Ricardo Sueiras: Dit artikel bevat een nieuwsbrief over open source projecten op AWS, waaronder enkele gerelateerd aan machine learning en model deployment.
https://dev.to/aws/aws-open-source-newsletter-158-178k

Mastering Your AI Coworker: A Developer's Guide to ChatGPT door Andreas Bergström: Dit artikel biedt een diepgaande gids over hoe je kunt werken met AI zoals ChatGPT, wat nuttig kan zijn bij het begrijpen van hoe je je eigen machine learning model kunt inzetten.
https://dev.to/andreasbergstrom/mastering-your-ai-coworker-a-developers-guide-to-chatgpt-1gea

Build LLM-powered chatbot in 5 minutes using HugChat and Streamlit door Vishnu Sivan: Dit artikel laat zien hoe je snel een chatbot kunt bouwen met behulp van machine learning, wat je kan helpen bij het begrijpen van de stappen die nodig zijn om een model te implementeren.
https://dev.to/codemaker2015/build-llm-powered-chatbot-in-5-minutes-using-hugchat-and-streamlit-2f53

DevOps Toolchain and Technologies door Rain Leander: Dit artikel bespreekt verschillende DevOps-tools en technologieën, die nuttig kunnen zijn bij het implementeren van machine learning modellen.
https://dev.to/rainleander/devops-toolchain-and-technologies-3n0k

Applying a MLOps approach to Federated learning using ML Flow with NV Flare: A Healthcare use case door Bart: Dit artikel bespreekt hoe je een MLOps-aanpak kunt toepassen op federatief leren, wat nuttig kan zijn bij het begrijpen van hoe je machine learning modellen kunt implementeren in een gedistribueerde omgeving.
https://dev.to/dataroots/applying-a-mlops-approach-to-federated-learning-using-ml-flow-with-nv-flare-a-healthcare-use-case-5e2n